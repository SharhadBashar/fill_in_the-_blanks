{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, txt_path = None, csv_path = None):\n",
    "        self.txt_path = txt_path if txt_path else '../data/LFM/txt/'\n",
    "        self.csv_path = csv_path if csv_path else '../data/LFM/csv/'\n",
    "        \n",
    "    def txt_to_csv(self, filename, index_col = None, to_drop_col = None, to_drop_row = None):\n",
    "        if index_col:\n",
    "            df = pd.read_csv(os.path.join(self.txt_path, filename), index_col = index_col, delimiter = '\\t')\n",
    "        else:\n",
    "            pd.read_csv(os.path.join(self.txt_path, filename), delimiter = '\\t')\n",
    "        if to_drop_col:\n",
    "            df = df.drop(to_drop_col, axis = 1)\n",
    "        if to_drop_row:\n",
    "            df = df.dropna(subset = to_drop_row)\n",
    "        return df\n",
    "\n",
    "    def join_df(self, df_1, df_2, on, how = ''):\n",
    "        how = how if how else 'left'\n",
    "        return df_1.join(df_2, on = on, how = how, lsuffix = '_left')        \n",
    "    \n",
    "    def seperate_train_text(self, df, criteria):\n",
    "        train = df[df['gender'].isin(criteria)]\n",
    "        test = df[~df['gender'].isin(criteria)]\n",
    "        return train, test\n",
    "    def undersample():\n",
    "        None\n",
    "    def over_sample(self, df):\n",
    "        classes = df['gender'].value_counts().to_dict()\n",
    "        most = max(classes.values())\n",
    "        classes_list = []\n",
    "        for key in classes:\n",
    "            classes_list.append(df[df['gender'] == key]) \n",
    "        classes_sample = []\n",
    "        for i in range(1,len(classes_list)):\n",
    "            classes_sample.append(classes_list[i].sample(most, replace=True))\n",
    "        df_maybe = pd.concat(classes_sample)\n",
    "        final_df = pd.concat([df_maybe,classes_list[0]], axis=0)\n",
    "        final_df = final_df.reset_index(drop=True)\n",
    "        return final_df\n",
    "        \n",
    "    def save_csv(self, df, csv_name):\n",
    "        df.to_csv(os.path.join(self.csv_path, csv_name))\n",
    "        print('File saved at:', os.path.join(self.csv_path, csv_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved at: ../data/LFM/csv/lfm_train.csv\n",
      "File saved at: ../data/LFM/csv/lfm_test.csv\n"
     ]
    }
   ],
   "source": [
    "data = Data()\n",
    "df_users = data.txt_to_csv('LFM-1b_users.txt', \n",
    "                      index_col = 'user_id', \n",
    "                      to_drop_col = ['playcount', 'registered_unixtime'],\n",
    "                      to_drop_row = ['country'])\n",
    "df_users_additional_data_w = data.txt_to_csv('LFM-1b_user_count_allmusic_w.txt', index_col = 'user_id')\n",
    "df_users_additional_data_nw = data.txt_to_csv('LFM-1b_user_count_allmusic_nw.txt', index_col = 'user_id')\n",
    "df_users_additional_data = data.join_df(df_users_additional_data_w, df_users_additional_data_w, 'user_id', how = 'inner')\n",
    "df = data.join_df(df_users, df_users_additional_data, 'user_id', how = 'inner')\n",
    "train, test = data.seperate_train_text(df, ['m', 'f'])\n",
    "train = data.over_sample(train)\n",
    "data.save_csv(train, 'lfm_train.csv')\n",
    "data.save_csv(test, 'lfm_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f    36472\n",
      "m    36472\n",
      "Name: gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def eda(df):\n",
    "    print(df['gender'].value_counts())\n",
    "df = pd.read_csv('../data/LFM/csv/lfm_train.csv')\n",
    "eda(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prep_Data:\n",
    "    def __init__(self, df_name, to_drop, normalize, normalize_cols, csv_name, train = False, csv_path = None):\n",
    "        self.csv_path = csv_path if csv_path else '../data/LFM/csv/'\n",
    "        df = pd.read_csv(os.path.join(self.csv_path, df_name))\n",
    "        df = self.drop_cols(df, to_drop)\n",
    "        df = self.normalize(df, normalize, normalize_cols)\n",
    "        if train:\n",
    "            df, to_drop = self.remove_corr(df, normalize_cols)\n",
    "            df = self.translate_target(df)\n",
    "        self.save_data(df, csv_name)\n",
    "    \n",
    "    def drop_cols(self, df, to_drop):\n",
    "        return df.drop(to_drop, axis = 1)\n",
    "\n",
    "    def normalize(self, df, normalize, normalize_cols):\n",
    "        if (normalize == 'minmax'):\n",
    "            scaler = MinMaxScaler()\n",
    "        elif (normalize == 'std'):\n",
    "            scaler = StandardScaler()\n",
    "        else:\n",
    "            scaler = Normalizer()\n",
    "        df[normalize_cols] = scaler.fit_transform(df[normalize_cols])\n",
    "        return df\n",
    "    \n",
    "    def remove_corr(self, df, X):\n",
    "        cor_matrix = df[X].corr().abs()\n",
    "        upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape), k = 1).astype(np.bool))\n",
    "        to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.97)]\n",
    "        print(to_drop)\n",
    "        df = df.drop(to_drop, axis = 1)\n",
    "        return df, to_drop\n",
    "    \n",
    "    def translate_target(self, df):\n",
    "        df['gender'] = df['gender'].replace({'f': 0, 'm': 1})\n",
    "        return df\n",
    "        \n",
    "    def save_data(self, df, csv_name):\n",
    "        df.to_csv(os.path.join(self.csv_path, csv_name))\n",
    "        print('File saved at:', os.path.join(self.csv_path, csv_name))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = ['rnb', 'rap', 'electronic', \n",
    "#      'rock', 'new age', 'classical',\n",
    "#      'reggae', 'blues', 'country', 'world',\n",
    "#      'folk', 'easy listening', 'jazz', 'vocal', \n",
    "#      'children\\'s', 'punk', 'alternative', 'spoken word', \n",
    "#      'pop', 'heavy metal']\n",
    "# X_after = ['rnb', 'rap', 'electronic', \n",
    "#      'rock', 'new age', 'classical',\n",
    "#      'reggae', 'blues', 'country', 'world',\n",
    "#      'folk', 'easy listening', 'jazz', 'vocal', \n",
    "#      'children\\'s', 'punk', 'spoken word', \n",
    "#      'pop', 'heavy metal']\n",
    "X = ['rnb', 'rap', 'electronic', \n",
    "     'rock', 'new age', 'classical',\n",
    "     'reggae', 'blues', 'country', 'world',\n",
    "     'folk', 'easy listening', 'jazz', 'vocal', \n",
    "     'children\\'s', 'punk', 'alternative', 'spoken word', \n",
    "     'pop', 'heavy metal',\n",
    "     'rnb_left', 'rap_left', 'electronic_left', \n",
    "     'rock_left', 'new age_left', 'classical_left',\n",
    "     'reggae_left', 'blues_left', 'world_left',\n",
    "     'folk_left', 'easy listening_left', 'jazz_left', 'vocal_left', \n",
    "     'children\\'s_left', 'punk_left', 'alternative_left', 'spoken word_left', \n",
    "     'pop_left', 'heavy metal_left']\n",
    "X_after = ['rnb', 'rap', 'electronic', \n",
    "     'rock', 'new age', 'classical',\n",
    "     'reggae', 'blues', 'country', 'world',\n",
    "     'folk', 'easy listening', 'jazz', 'vocal', \n",
    "     'children\\'s', 'punk', 'alternative', 'spoken word', \n",
    "     'pop', 'heavy metal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rnb_left', 'rap_left', 'electronic_left', 'rock_left', 'new age_left', 'classical_left', 'reggae_left', 'blues_left', 'world_left', 'folk_left', 'easy listening_left', 'jazz_left', 'vocal_left', \"children's_left\", 'punk_left', 'alternative_left', 'spoken word_left', 'pop_left', 'heavy metal_left']\n",
      "File saved at: ../data/LFM/csv/lfm_train_normalize.csv\n",
      "File saved at: ../data/LFM/csv/lfm_test_normalize.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Prep_Data at 0x7fa14d5b6cd0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prep_Data('lfm_train.csv', \n",
    "          to_drop = ['country_left', 'age'], \n",
    "          normalize = 'std', \n",
    "          normalize_cols = X,\n",
    "          csv_name = 'lfm_train_normalize.csv',\n",
    "          train = True)\n",
    "\n",
    "Prep_Data('lfm_test.csv', \n",
    "          to_drop = ['country_left', 'age'], \n",
    "          normalize = '', \n",
    "          normalize_cols = X,\n",
    "          csv_name = 'lfm_test_normalize.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train:\n",
    "    def __init__(self, df_name, X, y, model_name, model_type = 'logistic_regression', model_path = None, csv_path = None):\n",
    "        self.model_type_dict = {\n",
    "            'logistic_regression': LogisticRegression(),\n",
    "            'sgd_classifier': SGDClassifier(),\n",
    "            'random_forest': RandomForestClassifier(n_estimators = 1000),\n",
    "            'linear_svc': LinearSVC(),\n",
    "            'svc': SVC(),\n",
    "            'decision_tree': DecisionTreeClassifier(),\n",
    "            'nn': MLPClassifier()\n",
    "        }\n",
    "        \n",
    "        self.model_path = model_path if csv_path else '../model/'\n",
    "        self.csv_path = csv_path if csv_path else '../data/LFM/csv/'\n",
    "        if not os.path.isdir(self.model_path):\n",
    "            os.makedir(self.model_path)\n",
    "        df = pd.read_csv(os.path.join(self.csv_path, df_name))\n",
    "        train_X, test_X, train_y, test_y = self.train_test_split(df, X, y)\n",
    "        self.evaluate(df, X, y, train_X, test_X, train_y, test_y, model_type)\n",
    "        model = self.train(df[X], df[y], model_type)\n",
    "        self.save_model(model, model_name, self.model_path)\n",
    "        \n",
    "    def train_test_split(self, df, X, y, split = 0.05):\n",
    "        return train_test_split(df[X], df[y], test_size = split, shuffle = True)\n",
    "    \n",
    "    def evaluate(self, df, X, y, train_X, test_X, train_y, test_y, model_type):\n",
    "        model = self.model_type_dict[model_type]\n",
    "        model.fit(train_X, train_y)\n",
    "        # model.fit(df[X], df[y])\n",
    "        print(model_type, 'has an accuracy of:', model.score(test_X, test_y))\n",
    "    \n",
    "    def train(self, X, y, model_type):\n",
    "        start = time.time()\n",
    "        model = self.model_type_dict[model_type]\n",
    "        model.fit(X, y)\n",
    "        print('Model training took {}s'.format(time.time() - start))\n",
    "        return model\n",
    "        \n",
    "    def save_model(self, model, model_name, model_path):\n",
    "        pickle.dump(model, open(os.path.join(model_path, model_name), 'wb'))\n",
    "        print('Model saved at:',  os.path.join(model_path, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest has an accuracy of: 0.9311951754385965\n",
      "Model training took 179.51963901519775s\n",
      "Model saved at: ../model/model.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Train at 0x7fa14d597850>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train('lfm_train_normalize.csv',\n",
    "      X = X_after,\n",
    "      y = 'gender',\n",
    "      model_name = 'model.pkl',\n",
    "      model_type = 'random_forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67cd72ff27ae8893a953a45c4a70704668d46d68477d785131dc39711e1566da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
